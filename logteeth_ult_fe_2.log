I0307 09:21:52.579149 2997859264 caffe.cpp:211] Use CPU.
I0307 09:21:52.580488 2997859264 solver.cpp:44] Initializing solver from parameters: 
test_iter: 5
test_interval: 100
base_lr: 0.01
display: 10
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 100
snapshot_prefix: "model_snapshot/snap_fe"
solver_mode: CPU
net: "model/train_val_feature_scaled.prototxt"
train_state {
  level: 0
  stage: ""
}
I0307 09:21:52.581411 2997859264 solver.cpp:87] Creating training net from net file: model/train_val_feature_scaled.prototxt
I0307 09:21:52.581668 2997859264 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0307 09:21:52.581684 2997859264 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0307 09:21:52.581689 2997859264 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0307 09:21:52.581809 2997859264 layer_factory.hpp:77] Creating layer data
I0307 09:21:52.581998 2997859264 db_lmdb.cpp:35] Opened lmdb train_lmdb
I0307 09:21:52.582063 2997859264 net.cpp:84] Creating Layer data
I0307 09:21:52.582073 2997859264 net.cpp:380] data -> data
I0307 09:21:52.582087 2997859264 net.cpp:380] data -> label
I0307 09:21:52.582103 2997859264 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0307 09:21:52.582648 2997859264 data_layer.cpp:45] output data size: 256,1,50,50
I0307 09:21:52.594633 2997859264 net.cpp:122] Setting up data
I0307 09:21:52.594662 2997859264 net.cpp:129] Top shape: 256 1 50 50 (640000)
I0307 09:21:52.594677 2997859264 net.cpp:129] Top shape: 256 (256)
I0307 09:21:52.594686 2997859264 net.cpp:137] Memory required for data: 2561024
I0307 09:21:52.594699 2997859264 layer_factory.hpp:77] Creating layer conv1
I0307 09:21:52.594724 2997859264 net.cpp:84] Creating Layer conv1
I0307 09:21:52.594733 2997859264 net.cpp:406] conv1 <- data
I0307 09:21:52.594745 2997859264 net.cpp:380] conv1 -> conv1
I0307 09:21:52.595438 2997859264 net.cpp:122] Setting up conv1
I0307 09:21:52.595453 2997859264 net.cpp:129] Top shape: 256 20 46 46 (10833920)
I0307 09:21:52.596475 2997859264 net.cpp:137] Memory required for data: 45896704
I0307 09:21:52.596496 2997859264 layer_factory.hpp:77] Creating layer pool1
I0307 09:21:52.596509 2997859264 net.cpp:84] Creating Layer pool1
I0307 09:21:52.596516 2997859264 net.cpp:406] pool1 <- conv1
I0307 09:21:52.596524 2997859264 net.cpp:380] pool1 -> pool1
I0307 09:21:52.596544 2997859264 net.cpp:122] Setting up pool1
I0307 09:21:52.596552 2997859264 net.cpp:129] Top shape: 256 20 23 23 (2708480)
I0307 09:21:52.596561 2997859264 net.cpp:137] Memory required for data: 56730624
I0307 09:21:52.596568 2997859264 layer_factory.hpp:77] Creating layer conv2
I0307 09:21:52.596586 2997859264 net.cpp:84] Creating Layer conv2
I0307 09:21:52.596593 2997859264 net.cpp:406] conv2 <- pool1
I0307 09:21:52.596603 2997859264 net.cpp:380] conv2 -> conv2
I0307 09:21:52.597044 2997859264 net.cpp:122] Setting up conv2
I0307 09:21:52.597056 2997859264 net.cpp:129] Top shape: 256 50 19 19 (4620800)
I0307 09:21:52.597064 2997859264 net.cpp:137] Memory required for data: 75213824
I0307 09:21:52.597071 2997859264 layer_factory.hpp:77] Creating layer pool2
I0307 09:21:52.597080 2997859264 net.cpp:84] Creating Layer pool2
I0307 09:21:52.597092 2997859264 net.cpp:406] pool2 <- conv2
I0307 09:21:52.597101 2997859264 net.cpp:380] pool2 -> pool2
I0307 09:21:52.597115 2997859264 net.cpp:122] Setting up pool2
I0307 09:21:52.597122 2997859264 net.cpp:129] Top shape: 256 50 10 10 (1280000)
I0307 09:21:52.597148 2997859264 net.cpp:137] Memory required for data: 80333824
I0307 09:21:52.597157 2997859264 layer_factory.hpp:77] Creating layer ip1
I0307 09:21:52.597168 2997859264 net.cpp:84] Creating Layer ip1
I0307 09:21:52.597177 2997859264 net.cpp:406] ip1 <- pool2
I0307 09:21:52.597185 2997859264 net.cpp:380] ip1 -> ip1
I0307 09:21:52.622689 2997859264 net.cpp:122] Setting up ip1
I0307 09:21:52.622714 2997859264 net.cpp:129] Top shape: 256 500 (128000)
I0307 09:21:52.622721 2997859264 net.cpp:137] Memory required for data: 80845824
I0307 09:21:52.622732 2997859264 layer_factory.hpp:77] Creating layer relu1
I0307 09:21:52.622748 2997859264 net.cpp:84] Creating Layer relu1
I0307 09:21:52.622753 2997859264 net.cpp:406] relu1 <- ip1
I0307 09:21:52.622759 2997859264 net.cpp:367] relu1 -> ip1 (in-place)
I0307 09:21:52.622769 2997859264 net.cpp:122] Setting up relu1
I0307 09:21:52.622776 2997859264 net.cpp:129] Top shape: 256 500 (128000)
I0307 09:21:52.622782 2997859264 net.cpp:137] Memory required for data: 81357824
I0307 09:21:52.622786 2997859264 layer_factory.hpp:77] Creating layer drop1
I0307 09:21:52.622792 2997859264 net.cpp:84] Creating Layer drop1
I0307 09:21:52.622797 2997859264 net.cpp:406] drop1 <- ip1
I0307 09:21:52.622802 2997859264 net.cpp:367] drop1 -> ip1 (in-place)
I0307 09:21:52.622812 2997859264 net.cpp:122] Setting up drop1
I0307 09:21:52.622817 2997859264 net.cpp:129] Top shape: 256 500 (128000)
I0307 09:21:52.622822 2997859264 net.cpp:137] Memory required for data: 81869824
I0307 09:21:52.622826 2997859264 layer_factory.hpp:77] Creating layer ip2
I0307 09:21:52.622838 2997859264 net.cpp:84] Creating Layer ip2
I0307 09:21:52.622843 2997859264 net.cpp:406] ip2 <- ip1
I0307 09:21:52.622856 2997859264 net.cpp:380] ip2 -> ip2
I0307 09:21:52.622879 2997859264 net.cpp:122] Setting up ip2
I0307 09:21:52.622884 2997859264 net.cpp:129] Top shape: 256 2 (512)
I0307 09:21:52.622889 2997859264 net.cpp:137] Memory required for data: 81871872
I0307 09:21:52.622895 2997859264 layer_factory.hpp:77] Creating layer loss
I0307 09:21:52.622900 2997859264 net.cpp:84] Creating Layer loss
I0307 09:21:52.622905 2997859264 net.cpp:406] loss <- ip2
I0307 09:21:52.622908 2997859264 net.cpp:406] loss <- label
I0307 09:21:52.622916 2997859264 net.cpp:380] loss -> loss
I0307 09:21:52.622928 2997859264 layer_factory.hpp:77] Creating layer loss
I0307 09:21:52.622939 2997859264 net.cpp:122] Setting up loss
I0307 09:21:52.622943 2997859264 net.cpp:129] Top shape: (1)
I0307 09:21:52.622947 2997859264 net.cpp:132]     with loss weight 1
I0307 09:21:52.622988 2997859264 net.cpp:137] Memory required for data: 81871876
I0307 09:21:52.622993 2997859264 net.cpp:198] loss needs backward computation.
I0307 09:21:52.622998 2997859264 net.cpp:198] ip2 needs backward computation.
I0307 09:21:52.623003 2997859264 net.cpp:198] drop1 needs backward computation.
I0307 09:21:52.623006 2997859264 net.cpp:198] relu1 needs backward computation.
I0307 09:21:52.623010 2997859264 net.cpp:198] ip1 needs backward computation.
I0307 09:21:52.623014 2997859264 net.cpp:198] pool2 needs backward computation.
I0307 09:21:52.623018 2997859264 net.cpp:198] conv2 needs backward computation.
I0307 09:21:52.623023 2997859264 net.cpp:198] pool1 needs backward computation.
I0307 09:21:52.623028 2997859264 net.cpp:198] conv1 needs backward computation.
I0307 09:21:52.623033 2997859264 net.cpp:200] data does not need backward computation.
I0307 09:21:52.623036 2997859264 net.cpp:242] This network produces output loss
I0307 09:21:52.623044 2997859264 net.cpp:255] Network initialization done.
I0307 09:21:52.623296 2997859264 solver.cpp:173] Creating test net (#0) specified by net file: model/train_val_feature_scaled.prototxt
I0307 09:21:52.623322 2997859264 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0307 09:21:52.623333 2997859264 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "val_lmdb"
    batch_size: 60
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0307 09:21:52.623463 2997859264 layer_factory.hpp:77] Creating layer data
I0307 09:21:52.623536 2997859264 db_lmdb.cpp:35] Opened lmdb val_lmdb
I0307 09:21:52.623579 2997859264 net.cpp:84] Creating Layer data
I0307 09:21:52.623589 2997859264 net.cpp:380] data -> data
I0307 09:21:52.624590 2997859264 net.cpp:380] data -> label
I0307 09:21:52.624632 2997859264 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I0307 09:21:52.624730 2997859264 data_layer.cpp:45] output data size: 60,1,50,50
I0307 09:21:52.626140 2997859264 net.cpp:122] Setting up data
I0307 09:21:52.626155 2997859264 net.cpp:129] Top shape: 60 1 50 50 (150000)
I0307 09:21:52.626163 2997859264 net.cpp:129] Top shape: 60 (60)
I0307 09:21:52.626168 2997859264 net.cpp:137] Memory required for data: 600240
I0307 09:21:52.626173 2997859264 layer_factory.hpp:77] Creating layer label_data_1_split
I0307 09:21:52.626180 2997859264 net.cpp:84] Creating Layer label_data_1_split
I0307 09:21:52.626185 2997859264 net.cpp:406] label_data_1_split <- label
I0307 09:21:52.626191 2997859264 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0307 09:21:52.626199 2997859264 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0307 09:21:52.626207 2997859264 net.cpp:122] Setting up label_data_1_split
I0307 09:21:52.626211 2997859264 net.cpp:129] Top shape: 60 (60)
I0307 09:21:52.626216 2997859264 net.cpp:129] Top shape: 60 (60)
I0307 09:21:52.626220 2997859264 net.cpp:137] Memory required for data: 600720
I0307 09:21:52.626225 2997859264 layer_factory.hpp:77] Creating layer conv1
I0307 09:21:52.626237 2997859264 net.cpp:84] Creating Layer conv1
I0307 09:21:52.626243 2997859264 net.cpp:406] conv1 <- data
I0307 09:21:52.626248 2997859264 net.cpp:380] conv1 -> conv1
I0307 09:21:52.626281 2997859264 net.cpp:122] Setting up conv1
I0307 09:21:52.626286 2997859264 net.cpp:129] Top shape: 60 20 46 46 (2539200)
I0307 09:21:52.626291 2997859264 net.cpp:137] Memory required for data: 10757520
I0307 09:21:52.626298 2997859264 layer_factory.hpp:77] Creating layer pool1
I0307 09:21:52.626305 2997859264 net.cpp:84] Creating Layer pool1
I0307 09:21:52.626309 2997859264 net.cpp:406] pool1 <- conv1
I0307 09:21:52.626314 2997859264 net.cpp:380] pool1 -> pool1
I0307 09:21:52.626322 2997859264 net.cpp:122] Setting up pool1
I0307 09:21:52.626327 2997859264 net.cpp:129] Top shape: 60 20 23 23 (634800)
I0307 09:21:52.626333 2997859264 net.cpp:137] Memory required for data: 13296720
I0307 09:21:52.626338 2997859264 layer_factory.hpp:77] Creating layer conv2
I0307 09:21:52.626345 2997859264 net.cpp:84] Creating Layer conv2
I0307 09:21:52.626363 2997859264 net.cpp:406] conv2 <- pool1
I0307 09:21:52.626369 2997859264 net.cpp:380] conv2 -> conv2
I0307 09:21:52.626646 2997859264 net.cpp:122] Setting up conv2
I0307 09:21:52.626652 2997859264 net.cpp:129] Top shape: 60 50 19 19 (1083000)
I0307 09:21:52.626657 2997859264 net.cpp:137] Memory required for data: 17628720
I0307 09:21:52.626663 2997859264 layer_factory.hpp:77] Creating layer pool2
I0307 09:21:52.626668 2997859264 net.cpp:84] Creating Layer pool2
I0307 09:21:52.626672 2997859264 net.cpp:406] pool2 <- conv2
I0307 09:21:52.626677 2997859264 net.cpp:380] pool2 -> pool2
I0307 09:21:52.626684 2997859264 net.cpp:122] Setting up pool2
I0307 09:21:52.626688 2997859264 net.cpp:129] Top shape: 60 50 10 10 (300000)
I0307 09:21:52.626693 2997859264 net.cpp:137] Memory required for data: 18828720
I0307 09:21:52.626698 2997859264 layer_factory.hpp:77] Creating layer ip1
I0307 09:21:52.626703 2997859264 net.cpp:84] Creating Layer ip1
I0307 09:21:52.626708 2997859264 net.cpp:406] ip1 <- pool2
I0307 09:21:52.626716 2997859264 net.cpp:380] ip1 -> ip1
I0307 09:21:52.656142 2997859264 net.cpp:122] Setting up ip1
I0307 09:21:52.656165 2997859264 net.cpp:129] Top shape: 60 500 (30000)
I0307 09:21:52.656173 2997859264 net.cpp:137] Memory required for data: 18948720
I0307 09:21:52.656183 2997859264 layer_factory.hpp:77] Creating layer relu1
I0307 09:21:52.656193 2997859264 net.cpp:84] Creating Layer relu1
I0307 09:21:52.656198 2997859264 net.cpp:406] relu1 <- ip1
I0307 09:21:52.656205 2997859264 net.cpp:367] relu1 -> ip1 (in-place)
I0307 09:21:52.656213 2997859264 net.cpp:122] Setting up relu1
I0307 09:21:52.656219 2997859264 net.cpp:129] Top shape: 60 500 (30000)
I0307 09:21:52.656224 2997859264 net.cpp:137] Memory required for data: 19068720
I0307 09:21:52.656227 2997859264 layer_factory.hpp:77] Creating layer drop1
I0307 09:21:52.656235 2997859264 net.cpp:84] Creating Layer drop1
I0307 09:21:52.656239 2997859264 net.cpp:406] drop1 <- ip1
I0307 09:21:52.656265 2997859264 net.cpp:367] drop1 -> ip1 (in-place)
I0307 09:21:52.656302 2997859264 net.cpp:122] Setting up drop1
I0307 09:21:52.656318 2997859264 net.cpp:129] Top shape: 60 500 (30000)
I0307 09:21:52.656324 2997859264 net.cpp:137] Memory required for data: 19188720
I0307 09:21:52.656329 2997859264 layer_factory.hpp:77] Creating layer ip2
I0307 09:21:52.656339 2997859264 net.cpp:84] Creating Layer ip2
I0307 09:21:52.656343 2997859264 net.cpp:406] ip2 <- ip1
I0307 09:21:52.656350 2997859264 net.cpp:380] ip2 -> ip2
I0307 09:21:52.656373 2997859264 net.cpp:122] Setting up ip2
I0307 09:21:52.656378 2997859264 net.cpp:129] Top shape: 60 2 (120)
I0307 09:21:52.656383 2997859264 net.cpp:137] Memory required for data: 19189200
I0307 09:21:52.656389 2997859264 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0307 09:21:52.656395 2997859264 net.cpp:84] Creating Layer ip2_ip2_0_split
I0307 09:21:52.656399 2997859264 net.cpp:406] ip2_ip2_0_split <- ip2
I0307 09:21:52.656404 2997859264 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0307 09:21:52.656410 2997859264 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0307 09:21:52.656417 2997859264 net.cpp:122] Setting up ip2_ip2_0_split
I0307 09:21:52.656421 2997859264 net.cpp:129] Top shape: 60 2 (120)
I0307 09:21:52.656425 2997859264 net.cpp:129] Top shape: 60 2 (120)
I0307 09:21:52.656430 2997859264 net.cpp:137] Memory required for data: 19190160
I0307 09:21:52.656435 2997859264 layer_factory.hpp:77] Creating layer loss
I0307 09:21:52.656440 2997859264 net.cpp:84] Creating Layer loss
I0307 09:21:52.656445 2997859264 net.cpp:406] loss <- ip2_ip2_0_split_0
I0307 09:21:52.656450 2997859264 net.cpp:406] loss <- label_data_1_split_0
I0307 09:21:52.656457 2997859264 net.cpp:380] loss -> loss
I0307 09:21:52.656464 2997859264 layer_factory.hpp:77] Creating layer loss
I0307 09:21:52.656474 2997859264 net.cpp:122] Setting up loss
I0307 09:21:52.656479 2997859264 net.cpp:129] Top shape: (1)
I0307 09:21:52.656483 2997859264 net.cpp:132]     with loss weight 1
I0307 09:21:52.656491 2997859264 net.cpp:137] Memory required for data: 19190164
I0307 09:21:52.656494 2997859264 layer_factory.hpp:77] Creating layer accuracy
I0307 09:21:52.656502 2997859264 net.cpp:84] Creating Layer accuracy
I0307 09:21:52.656507 2997859264 net.cpp:406] accuracy <- ip2_ip2_0_split_1
I0307 09:21:52.656510 2997859264 net.cpp:406] accuracy <- label_data_1_split_1
I0307 09:21:52.656517 2997859264 net.cpp:380] accuracy -> accuracy
I0307 09:21:52.656523 2997859264 net.cpp:122] Setting up accuracy
I0307 09:21:52.656528 2997859264 net.cpp:129] Top shape: (1)
I0307 09:21:52.656533 2997859264 net.cpp:137] Memory required for data: 19190168
I0307 09:21:52.656536 2997859264 net.cpp:200] accuracy does not need backward computation.
I0307 09:21:52.656541 2997859264 net.cpp:198] loss needs backward computation.
I0307 09:21:52.656546 2997859264 net.cpp:198] ip2_ip2_0_split needs backward computation.
I0307 09:21:52.656550 2997859264 net.cpp:198] ip2 needs backward computation.
I0307 09:21:52.656554 2997859264 net.cpp:198] drop1 needs backward computation.
I0307 09:21:52.656558 2997859264 net.cpp:198] relu1 needs backward computation.
I0307 09:21:52.656563 2997859264 net.cpp:198] ip1 needs backward computation.
I0307 09:21:52.656568 2997859264 net.cpp:198] pool2 needs backward computation.
I0307 09:21:52.656571 2997859264 net.cpp:198] conv2 needs backward computation.
I0307 09:21:52.656575 2997859264 net.cpp:198] pool1 needs backward computation.
I0307 09:21:52.656580 2997859264 net.cpp:198] conv1 needs backward computation.
I0307 09:21:52.656584 2997859264 net.cpp:200] label_data_1_split does not need backward computation.
I0307 09:21:52.656589 2997859264 net.cpp:200] data does not need backward computation.
I0307 09:21:52.656594 2997859264 net.cpp:242] This network produces output accuracy
I0307 09:21:52.656599 2997859264 net.cpp:242] This network produces output loss
I0307 09:21:52.656606 2997859264 net.cpp:255] Network initialization done.
I0307 09:21:52.656668 2997859264 solver.cpp:56] Solver scaffolding done.
I0307 09:21:52.656719 2997859264 caffe.cpp:248] Starting Optimization
I0307 09:21:52.656726 2997859264 solver.cpp:273] Solving LeNet
I0307 09:21:52.656730 2997859264 solver.cpp:274] Learning Rate Policy: step
I0307 09:21:52.663204 2997859264 solver.cpp:331] Iteration 0, Testing net (#0)
I0307 09:21:52.802947 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:21:52.975595 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.493333
I0307 09:21:52.975623 2997859264 solver.cpp:398]     Test net output #1: loss = 0.708246 (* 1 = 0.708246 loss)
I0307 09:21:53.576822 2997859264 solver.cpp:219] Iteration 0 (0 iter/s, 0.92s/10 iters), loss = 0.709497
I0307 09:21:53.576853 2997859264 solver.cpp:238]     Train net output #0: loss = 0.709497 (* 1 = 0.709497 loss)
I0307 09:21:53.576894 2997859264 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0307 09:21:58.547243 2997859264 solver.cpp:219] Iteration 10 (2.01207 iter/s, 4.97s/10 iters), loss = 0.588646
I0307 09:21:58.547274 2997859264 solver.cpp:238]     Train net output #0: loss = 0.588646 (* 1 = 0.588646 loss)
I0307 09:21:58.547282 2997859264 sgd_solver.cpp:105] Iteration 10, lr = 0.01
I0307 09:22:03.466532 2997859264 solver.cpp:219] Iteration 20 (2.03293 iter/s, 4.919s/10 iters), loss = 0.5227
I0307 09:22:03.466565 2997859264 solver.cpp:238]     Train net output #0: loss = 0.5227 (* 1 = 0.5227 loss)
I0307 09:22:03.466573 2997859264 sgd_solver.cpp:105] Iteration 20, lr = 0.01
I0307 09:22:08.396392 2997859264 solver.cpp:219] Iteration 30 (2.02881 iter/s, 4.929s/10 iters), loss = 0.545091
I0307 09:22:08.396425 2997859264 solver.cpp:238]     Train net output #0: loss = 0.545091 (* 1 = 0.545091 loss)
I0307 09:22:08.396433 2997859264 sgd_solver.cpp:105] Iteration 30, lr = 0.01
I0307 09:22:13.309725 2997859264 solver.cpp:219] Iteration 40 (2.03542 iter/s, 4.913s/10 iters), loss = 0.415445
I0307 09:22:13.309757 2997859264 solver.cpp:238]     Train net output #0: loss = 0.415445 (* 1 = 0.415445 loss)
I0307 09:22:13.309764 2997859264 sgd_solver.cpp:105] Iteration 40, lr = 0.01
I0307 09:22:13.319262 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:22:18.232134 2997859264 solver.cpp:219] Iteration 50 (2.03169 iter/s, 4.922s/10 iters), loss = 0.407064
I0307 09:22:18.232167 2997859264 solver.cpp:238]     Train net output #0: loss = 0.407064 (* 1 = 0.407064 loss)
I0307 09:22:18.232174 2997859264 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0307 09:22:23.155551 2997859264 solver.cpp:219] Iteration 60 (2.03128 iter/s, 4.923s/10 iters), loss = 0.38116
I0307 09:22:23.155606 2997859264 solver.cpp:238]     Train net output #0: loss = 0.38116 (* 1 = 0.38116 loss)
I0307 09:22:23.155613 2997859264 sgd_solver.cpp:105] Iteration 60, lr = 0.01
I0307 09:22:28.429553 2997859264 solver.cpp:219] Iteration 70 (1.89645 iter/s, 5.273s/10 iters), loss = 0.319641
I0307 09:22:28.429617 2997859264 solver.cpp:238]     Train net output #0: loss = 0.319641 (* 1 = 0.319641 loss)
I0307 09:22:28.429628 2997859264 sgd_solver.cpp:105] Iteration 70, lr = 0.01
I0307 09:22:33.529587 2997859264 solver.cpp:219] Iteration 80 (1.96117 iter/s, 5.099s/10 iters), loss = 0.341128
I0307 09:22:33.529618 2997859264 solver.cpp:238]     Train net output #0: loss = 0.341128 (* 1 = 0.341128 loss)
I0307 09:22:33.529625 2997859264 sgd_solver.cpp:105] Iteration 80, lr = 0.01
I0307 09:22:36.030432 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:22:38.484442 2997859264 solver.cpp:219] Iteration 90 (2.01857 iter/s, 4.954s/10 iters), loss = 0.336466
I0307 09:22:38.484474 2997859264 solver.cpp:238]     Train net output #0: loss = 0.336466 (* 1 = 0.336466 loss)
I0307 09:22:38.484483 2997859264 sgd_solver.cpp:105] Iteration 90, lr = 0.01
I0307 09:22:43.238085 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_100.caffemodel
I0307 09:22:43.320878 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_100.solverstate
I0307 09:22:43.344349 2997859264 solver.cpp:331] Iteration 100, Testing net (#0)
I0307 09:22:43.529525 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:22:43.648672 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.886667
I0307 09:22:43.648703 2997859264 solver.cpp:398]     Test net output #1: loss = 0.318416 (* 1 = 0.318416 loss)
I0307 09:22:44.170374 2997859264 solver.cpp:219] Iteration 100 (1.75901 iter/s, 5.685s/10 iters), loss = 0.300314
I0307 09:22:44.170406 2997859264 solver.cpp:238]     Train net output #0: loss = 0.300314 (* 1 = 0.300314 loss)
I0307 09:22:44.170413 2997859264 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0307 09:22:49.470499 2997859264 solver.cpp:219] Iteration 110 (1.88679 iter/s, 5.3s/10 iters), loss = 0.303074
I0307 09:22:49.470532 2997859264 solver.cpp:238]     Train net output #0: loss = 0.303074 (* 1 = 0.303074 loss)
I0307 09:22:49.470541 2997859264 sgd_solver.cpp:105] Iteration 110, lr = 0.01
I0307 09:22:55.233992 2997859264 solver.cpp:219] Iteration 120 (1.73521 iter/s, 5.763s/10 iters), loss = 0.304769
I0307 09:22:55.234254 2997859264 solver.cpp:238]     Train net output #0: loss = 0.304769 (* 1 = 0.304769 loss)
I0307 09:22:55.234266 2997859264 sgd_solver.cpp:105] Iteration 120, lr = 0.01
I0307 09:23:00.740298 2997859264 solver.cpp:219] Iteration 130 (1.8162 iter/s, 5.506s/10 iters), loss = 0.258935
I0307 09:23:00.740329 2997859264 solver.cpp:238]     Train net output #0: loss = 0.258935 (* 1 = 0.258935 loss)
I0307 09:23:00.740336 2997859264 sgd_solver.cpp:105] Iteration 130, lr = 0.01
I0307 09:23:00.747999 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:23:06.017021 2997859264 solver.cpp:219] Iteration 140 (1.89538 iter/s, 5.276s/10 iters), loss = 0.269089
I0307 09:23:06.017057 2997859264 solver.cpp:238]     Train net output #0: loss = 0.269089 (* 1 = 0.269089 loss)
I0307 09:23:06.017067 2997859264 sgd_solver.cpp:105] Iteration 140, lr = 0.01
I0307 09:23:11.277287 2997859264 solver.cpp:219] Iteration 150 (1.90114 iter/s, 5.26s/10 iters), loss = 0.28786
I0307 09:23:11.277317 2997859264 solver.cpp:238]     Train net output #0: loss = 0.28786 (* 1 = 0.28786 loss)
I0307 09:23:11.277323 2997859264 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0307 09:23:16.529880 2997859264 solver.cpp:219] Iteration 160 (1.90404 iter/s, 5.252s/10 iters), loss = 0.223019
I0307 09:23:16.529911 2997859264 solver.cpp:238]     Train net output #0: loss = 0.223019 (* 1 = 0.223019 loss)
I0307 09:23:16.529920 2997859264 sgd_solver.cpp:105] Iteration 160, lr = 0.01
I0307 09:23:21.601297 2997859264 solver.cpp:219] Iteration 170 (1.972 iter/s, 5.071s/10 iters), loss = 0.298963
I0307 09:23:21.601328 2997859264 solver.cpp:238]     Train net output #0: loss = 0.298963 (* 1 = 0.298963 loss)
I0307 09:23:21.601336 2997859264 sgd_solver.cpp:105] Iteration 170, lr = 0.01
I0307 09:23:23.712537 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:23:26.981163 2997859264 solver.cpp:219] Iteration 180 (1.85908 iter/s, 5.379s/10 iters), loss = 0.239222
I0307 09:23:26.982065 2997859264 solver.cpp:238]     Train net output #0: loss = 0.239222 (* 1 = 0.239222 loss)
I0307 09:23:26.982079 2997859264 sgd_solver.cpp:105] Iteration 180, lr = 0.01
I0307 09:23:32.284888 2997859264 solver.cpp:219] Iteration 190 (1.88608 iter/s, 5.302s/10 iters), loss = 0.26677
I0307 09:23:32.284920 2997859264 solver.cpp:238]     Train net output #0: loss = 0.26677 (* 1 = 0.26677 loss)
I0307 09:23:32.284929 2997859264 sgd_solver.cpp:105] Iteration 190, lr = 0.01
I0307 09:23:36.945189 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_200.caffemodel
I0307 09:23:37.027868 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_200.solverstate
I0307 09:23:37.051861 2997859264 solver.cpp:331] Iteration 200, Testing net (#0)
I0307 09:23:37.228168 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:23:37.351583 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.903333
I0307 09:23:37.351616 2997859264 solver.cpp:398]     Test net output #1: loss = 0.226186 (* 1 = 0.226186 loss)
I0307 09:23:37.865286 2997859264 solver.cpp:219] Iteration 200 (1.79211 iter/s, 5.58s/10 iters), loss = 0.239989
I0307 09:23:37.865319 2997859264 solver.cpp:238]     Train net output #0: loss = 0.239989 (* 1 = 0.239989 loss)
I0307 09:23:37.865326 2997859264 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0307 09:23:43.730065 2997859264 solver.cpp:219] Iteration 210 (1.70532 iter/s, 5.864s/10 iters), loss = 0.260789
I0307 09:23:43.730103 2997859264 solver.cpp:238]     Train net output #0: loss = 0.260789 (* 1 = 0.260789 loss)
I0307 09:23:43.730113 2997859264 sgd_solver.cpp:105] Iteration 210, lr = 0.01
I0307 09:23:48.601017 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:23:49.115288 2997859264 solver.cpp:219] Iteration 220 (1.85701 iter/s, 5.385s/10 iters), loss = 0.201185
I0307 09:23:49.115317 2997859264 solver.cpp:238]     Train net output #0: loss = 0.201185 (* 1 = 0.201185 loss)
I0307 09:23:49.115324 2997859264 sgd_solver.cpp:105] Iteration 220, lr = 0.01
I0307 09:23:54.613322 2997859264 solver.cpp:219] Iteration 230 (1.81917 iter/s, 5.497s/10 iters), loss = 0.196359
I0307 09:23:54.613363 2997859264 solver.cpp:238]     Train net output #0: loss = 0.196359 (* 1 = 0.196359 loss)
I0307 09:23:54.613374 2997859264 sgd_solver.cpp:105] Iteration 230, lr = 0.01
I0307 09:23:59.984122 2997859264 solver.cpp:219] Iteration 240 (1.8622 iter/s, 5.37s/10 iters), loss = 0.204186
I0307 09:23:59.985023 2997859264 solver.cpp:238]     Train net output #0: loss = 0.204186 (* 1 = 0.204186 loss)
I0307 09:23:59.985034 2997859264 sgd_solver.cpp:105] Iteration 240, lr = 0.01
I0307 09:24:05.142071 2997859264 solver.cpp:219] Iteration 250 (1.93911 iter/s, 5.157s/10 iters), loss = 0.248923
I0307 09:24:05.142102 2997859264 solver.cpp:238]     Train net output #0: loss = 0.248923 (* 1 = 0.248923 loss)
I0307 09:24:05.142109 2997859264 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0307 09:24:10.353657 2997859264 solver.cpp:219] Iteration 260 (1.91902 iter/s, 5.211s/10 iters), loss = 0.205769
I0307 09:24:10.353704 2997859264 solver.cpp:238]     Train net output #0: loss = 0.205769 (* 1 = 0.205769 loss)
I0307 09:24:10.353713 2997859264 sgd_solver.cpp:105] Iteration 260, lr = 0.01
I0307 09:24:12.501868 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:24:15.591450 2997859264 solver.cpp:219] Iteration 270 (1.90949 iter/s, 5.237s/10 iters), loss = 0.207344
I0307 09:24:15.591483 2997859264 solver.cpp:238]     Train net output #0: loss = 0.207344 (* 1 = 0.207344 loss)
I0307 09:24:15.591491 2997859264 sgd_solver.cpp:105] Iteration 270, lr = 0.01
I0307 09:24:20.842885 2997859264 solver.cpp:219] Iteration 280 (1.9044 iter/s, 5.251s/10 iters), loss = 0.171513
I0307 09:24:20.842936 2997859264 solver.cpp:238]     Train net output #0: loss = 0.171513 (* 1 = 0.171513 loss)
I0307 09:24:20.842947 2997859264 sgd_solver.cpp:105] Iteration 280, lr = 0.01
I0307 09:24:25.953800 2997859264 solver.cpp:219] Iteration 290 (1.95695 iter/s, 5.11s/10 iters), loss = 0.159973
I0307 09:24:25.953832 2997859264 solver.cpp:238]     Train net output #0: loss = 0.159973 (* 1 = 0.159973 loss)
I0307 09:24:25.953840 2997859264 sgd_solver.cpp:105] Iteration 290, lr = 0.01
I0307 09:24:30.554363 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_300.caffemodel
I0307 09:24:30.623432 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_300.solverstate
I0307 09:24:30.647430 2997859264 solver.cpp:331] Iteration 300, Testing net (#0)
I0307 09:24:30.884655 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:24:30.944628 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.906667
I0307 09:24:30.944658 2997859264 solver.cpp:398]     Test net output #1: loss = 0.22523 (* 1 = 0.22523 loss)
I0307 09:24:31.451023 2997859264 solver.cpp:219] Iteration 300 (1.81917 iter/s, 5.497s/10 iters), loss = 0.253901
I0307 09:24:31.451056 2997859264 solver.cpp:238]     Train net output #0: loss = 0.253901 (* 1 = 0.253901 loss)
I0307 09:24:31.451062 2997859264 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0307 09:24:36.033432 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:24:36.548275 2997859264 solver.cpp:219] Iteration 310 (1.96194 iter/s, 5.097s/10 iters), loss = 0.139822
I0307 09:24:36.548307 2997859264 solver.cpp:238]     Train net output #0: loss = 0.139822 (* 1 = 0.139822 loss)
I0307 09:24:36.548315 2997859264 sgd_solver.cpp:105] Iteration 310, lr = 0.01
I0307 09:24:41.637069 2997859264 solver.cpp:219] Iteration 320 (1.96541 iter/s, 5.088s/10 iters), loss = 0.161826
I0307 09:24:41.637101 2997859264 solver.cpp:238]     Train net output #0: loss = 0.161826 (* 1 = 0.161826 loss)
I0307 09:24:41.637109 2997859264 sgd_solver.cpp:105] Iteration 320, lr = 0.01
I0307 09:24:46.903128 2997859264 solver.cpp:219] Iteration 330 (1.89897 iter/s, 5.266s/10 iters), loss = 0.151786
I0307 09:24:46.903163 2997859264 solver.cpp:238]     Train net output #0: loss = 0.151786 (* 1 = 0.151786 loss)
I0307 09:24:46.903172 2997859264 sgd_solver.cpp:105] Iteration 330, lr = 0.01
I0307 09:24:52.259066 2997859264 solver.cpp:219] Iteration 340 (1.86741 iter/s, 5.355s/10 iters), loss = 0.200882
I0307 09:24:52.259096 2997859264 solver.cpp:238]     Train net output #0: loss = 0.200882 (* 1 = 0.200882 loss)
I0307 09:24:52.259104 2997859264 sgd_solver.cpp:105] Iteration 340, lr = 0.01
I0307 09:24:57.553840 2997859264 solver.cpp:219] Iteration 350 (1.88893 iter/s, 5.294s/10 iters), loss = 0.170992
I0307 09:24:57.553869 2997859264 solver.cpp:238]     Train net output #0: loss = 0.170992 (* 1 = 0.170992 loss)
I0307 09:24:57.553876 2997859264 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0307 09:24:59.143337 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:25:02.914721 2997859264 solver.cpp:219] Iteration 360 (1.86567 iter/s, 5.36s/10 iters), loss = 0.196379
I0307 09:25:02.915777 2997859264 solver.cpp:238]     Train net output #0: loss = 0.196379 (* 1 = 0.196379 loss)
I0307 09:25:02.915814 2997859264 sgd_solver.cpp:105] Iteration 360, lr = 0.01
I0307 09:25:08.497812 2997859264 solver.cpp:219] Iteration 370 (1.79147 iter/s, 5.582s/10 iters), loss = 0.117564
I0307 09:25:08.497844 2997859264 solver.cpp:238]     Train net output #0: loss = 0.117564 (* 1 = 0.117564 loss)
I0307 09:25:08.497851 2997859264 sgd_solver.cpp:105] Iteration 370, lr = 0.01
I0307 09:25:14.044495 2997859264 solver.cpp:219] Iteration 380 (1.8031 iter/s, 5.546s/10 iters), loss = 0.161869
I0307 09:25:14.044523 2997859264 solver.cpp:238]     Train net output #0: loss = 0.161869 (* 1 = 0.161869 loss)
I0307 09:25:14.044530 2997859264 sgd_solver.cpp:105] Iteration 380, lr = 0.01
I0307 09:25:19.878016 2997859264 solver.cpp:219] Iteration 390 (1.71438 iter/s, 5.833s/10 iters), loss = 0.1313
I0307 09:25:19.878046 2997859264 solver.cpp:238]     Train net output #0: loss = 0.1313 (* 1 = 0.1313 loss)
I0307 09:25:19.878054 2997859264 sgd_solver.cpp:105] Iteration 390, lr = 0.01
I0307 09:25:24.581943 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:25:25.125365 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_400.caffemodel
I0307 09:25:25.211629 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_400.solverstate
I0307 09:25:25.238700 2997859264 solver.cpp:331] Iteration 400, Testing net (#0)
I0307 09:25:25.556844 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.936667
I0307 09:25:25.556874 2997859264 solver.cpp:398]     Test net output #1: loss = 0.176669 (* 1 = 0.176669 loss)
I0307 09:25:26.115051 2997859264 solver.cpp:219] Iteration 400 (1.60333 iter/s, 6.237s/10 iters), loss = 0.124171
I0307 09:25:26.115080 2997859264 solver.cpp:238]     Train net output #0: loss = 0.124171 (* 1 = 0.124171 loss)
I0307 09:25:26.115087 2997859264 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0307 09:25:31.711635 2997859264 solver.cpp:219] Iteration 410 (1.78699 iter/s, 5.596s/10 iters), loss = 0.16435
I0307 09:25:31.711670 2997859264 solver.cpp:238]     Train net output #0: loss = 0.16435 (* 1 = 0.16435 loss)
I0307 09:25:31.711678 2997859264 sgd_solver.cpp:105] Iteration 410, lr = 0.01
I0307 09:25:37.002457 2997859264 solver.cpp:219] Iteration 420 (1.89036 iter/s, 5.29s/10 iters), loss = 0.104477
I0307 09:25:37.003295 2997859264 solver.cpp:238]     Train net output #0: loss = 0.104477 (* 1 = 0.104477 loss)
I0307 09:25:37.003306 2997859264 sgd_solver.cpp:105] Iteration 420, lr = 0.01
I0307 09:25:42.265015 2997859264 solver.cpp:219] Iteration 430 (1.90078 iter/s, 5.261s/10 iters), loss = 0.175037
I0307 09:25:42.265087 2997859264 solver.cpp:238]     Train net output #0: loss = 0.175037 (* 1 = 0.175037 loss)
I0307 09:25:42.265105 2997859264 sgd_solver.cpp:105] Iteration 430, lr = 0.01
I0307 09:25:47.522466 2997859264 solver.cpp:219] Iteration 440 (1.90223 iter/s, 5.257s/10 iters), loss = 0.154709
I0307 09:25:47.522508 2997859264 solver.cpp:238]     Train net output #0: loss = 0.154709 (* 1 = 0.154709 loss)
I0307 09:25:47.522516 2997859264 sgd_solver.cpp:105] Iteration 440, lr = 0.01
I0307 09:25:49.196517 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:25:52.938942 2997859264 solver.cpp:219] Iteration 450 (1.84638 iter/s, 5.416s/10 iters), loss = 0.147814
I0307 09:25:52.938989 2997859264 solver.cpp:238]     Train net output #0: loss = 0.147814 (* 1 = 0.147814 loss)
I0307 09:25:52.939002 2997859264 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0307 09:25:58.219696 2997859264 solver.cpp:219] Iteration 460 (1.89394 iter/s, 5.28s/10 iters), loss = 0.148493
I0307 09:25:58.219733 2997859264 solver.cpp:238]     Train net output #0: loss = 0.148493 (* 1 = 0.148493 loss)
I0307 09:25:58.219741 2997859264 sgd_solver.cpp:105] Iteration 460, lr = 0.01
I0307 09:26:03.768532 2997859264 solver.cpp:219] Iteration 470 (1.80245 iter/s, 5.548s/10 iters), loss = 0.140537
I0307 09:26:03.768566 2997859264 solver.cpp:238]     Train net output #0: loss = 0.140537 (* 1 = 0.140537 loss)
I0307 09:26:03.768574 2997859264 sgd_solver.cpp:105] Iteration 470, lr = 0.01
I0307 09:26:09.831732 2997859264 solver.cpp:219] Iteration 480 (1.64935 iter/s, 6.063s/10 iters), loss = 0.105384
I0307 09:26:09.832597 2997859264 solver.cpp:238]     Train net output #0: loss = 0.105384 (* 1 = 0.105384 loss)
I0307 09:26:09.832608 2997859264 sgd_solver.cpp:105] Iteration 480, lr = 0.01
I0307 09:26:14.321959 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:26:15.404763 2997859264 solver.cpp:219] Iteration 490 (1.79469 iter/s, 5.572s/10 iters), loss = 0.102513
I0307 09:26:15.404793 2997859264 solver.cpp:238]     Train net output #0: loss = 0.102513 (* 1 = 0.102513 loss)
I0307 09:26:15.404800 2997859264 sgd_solver.cpp:105] Iteration 490, lr = 0.01
I0307 09:26:20.150485 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_500.caffemodel
I0307 09:26:20.220916 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_500.solverstate
I0307 09:26:20.245335 2997859264 solver.cpp:331] Iteration 500, Testing net (#0)
I0307 09:26:20.245692 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:26:20.548044 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.953333
I0307 09:26:20.548074 2997859264 solver.cpp:398]     Test net output #1: loss = 0.1301 (* 1 = 0.1301 loss)
I0307 09:26:21.072893 2997859264 solver.cpp:219] Iteration 500 (1.76429 iter/s, 5.668s/10 iters), loss = 0.167693
I0307 09:26:21.072937 2997859264 solver.cpp:238]     Train net output #0: loss = 0.167693 (* 1 = 0.167693 loss)
I0307 09:26:21.072948 2997859264 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0307 09:26:26.352140 2997859264 solver.cpp:219] Iteration 510 (1.8943 iter/s, 5.279s/10 iters), loss = 0.165961
I0307 09:26:26.352172 2997859264 solver.cpp:238]     Train net output #0: loss = 0.165961 (* 1 = 0.165961 loss)
I0307 09:26:26.352180 2997859264 sgd_solver.cpp:105] Iteration 510, lr = 0.001
I0307 09:26:31.935798 2997859264 solver.cpp:219] Iteration 520 (1.79115 iter/s, 5.583s/10 iters), loss = 0.113069
I0307 09:26:31.935829 2997859264 solver.cpp:238]     Train net output #0: loss = 0.113069 (* 1 = 0.113069 loss)
I0307 09:26:31.935837 2997859264 sgd_solver.cpp:105] Iteration 520, lr = 0.001
I0307 09:26:37.172225 2997859264 solver.cpp:219] Iteration 530 (1.90985 iter/s, 5.236s/10 iters), loss = 0.112273
I0307 09:26:37.172255 2997859264 solver.cpp:238]     Train net output #0: loss = 0.112273 (* 1 = 0.112273 loss)
I0307 09:26:37.172263 2997859264 sgd_solver.cpp:105] Iteration 530, lr = 0.001
I0307 09:26:38.226182 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:26:42.445554 2997859264 solver.cpp:219] Iteration 540 (1.89645 iter/s, 5.273s/10 iters), loss = 0.0718424
I0307 09:26:42.446302 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0718424 (* 1 = 0.0718424 loss)
I0307 09:26:42.446312 2997859264 sgd_solver.cpp:105] Iteration 540, lr = 0.001
I0307 09:26:47.715006 2997859264 solver.cpp:219] Iteration 550 (1.89825 iter/s, 5.268s/10 iters), loss = 0.103725
I0307 09:26:47.715067 2997859264 solver.cpp:238]     Train net output #0: loss = 0.103725 (* 1 = 0.103725 loss)
I0307 09:26:47.715080 2997859264 sgd_solver.cpp:105] Iteration 550, lr = 0.001
I0307 09:26:52.962553 2997859264 solver.cpp:219] Iteration 560 (1.90585 iter/s, 5.247s/10 iters), loss = 0.115141
I0307 09:26:52.962584 2997859264 solver.cpp:238]     Train net output #0: loss = 0.115141 (* 1 = 0.115141 loss)
I0307 09:26:52.962591 2997859264 sgd_solver.cpp:105] Iteration 560, lr = 0.001
I0307 09:26:58.253298 2997859264 solver.cpp:219] Iteration 570 (1.89036 iter/s, 5.29s/10 iters), loss = 0.0761462
I0307 09:26:58.253329 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0761462 (* 1 = 0.0761462 loss)
I0307 09:26:58.253338 2997859264 sgd_solver.cpp:105] Iteration 570, lr = 0.001
I0307 09:27:01.945224 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:27:03.503895 2997859264 solver.cpp:219] Iteration 580 (1.90476 iter/s, 5.25s/10 iters), loss = 0.0927313
I0307 09:27:03.503928 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0927313 (* 1 = 0.0927313 loss)
I0307 09:27:03.503937 2997859264 sgd_solver.cpp:105] Iteration 580, lr = 0.001
I0307 09:27:08.838066 2997859264 solver.cpp:219] Iteration 590 (1.87477 iter/s, 5.334s/10 iters), loss = 0.084152
I0307 09:27:08.838095 2997859264 solver.cpp:238]     Train net output #0: loss = 0.084152 (* 1 = 0.084152 loss)
I0307 09:27:08.838104 2997859264 sgd_solver.cpp:105] Iteration 590, lr = 0.001
I0307 09:27:14.342871 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_600.caffemodel
I0307 09:27:14.449371 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_600.solverstate
I0307 09:27:14.504943 2997859264 solver.cpp:331] Iteration 600, Testing net (#0)
I0307 09:27:14.506049 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:27:14.849596 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.953333
I0307 09:27:14.849639 2997859264 solver.cpp:398]     Test net output #1: loss = 0.142309 (* 1 = 0.142309 loss)
I0307 09:27:15.391955 2997859264 solver.cpp:219] Iteration 600 (1.52602 iter/s, 6.553s/10 iters), loss = 0.0920523
I0307 09:27:15.391986 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0920523 (* 1 = 0.0920523 loss)
I0307 09:27:15.391994 2997859264 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0307 09:27:21.375308 2997859264 solver.cpp:219] Iteration 610 (1.6714 iter/s, 5.983s/10 iters), loss = 0.0942791
I0307 09:27:21.375345 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0942791 (* 1 = 0.0942791 loss)
I0307 09:27:21.375355 2997859264 sgd_solver.cpp:105] Iteration 610, lr = 0.001
I0307 09:27:27.058405 2997859264 solver.cpp:219] Iteration 620 (1.75963 iter/s, 5.683s/10 iters), loss = 0.0909608
I0307 09:27:27.058436 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0909608 (* 1 = 0.0909608 loss)
I0307 09:27:27.058444 2997859264 sgd_solver.cpp:105] Iteration 620, lr = 0.001
I0307 09:27:28.378587 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:27:33.422647 2997859264 solver.cpp:219] Iteration 630 (1.57134 iter/s, 6.364s/10 iters), loss = 0.0540646
I0307 09:27:33.422678 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0540646 (* 1 = 0.0540646 loss)
I0307 09:27:33.422688 2997859264 sgd_solver.cpp:105] Iteration 630, lr = 0.001
I0307 09:27:38.894992 2997859264 solver.cpp:219] Iteration 640 (1.82749 iter/s, 5.472s/10 iters), loss = 0.0840877
I0307 09:27:38.895040 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0840877 (* 1 = 0.0840877 loss)
I0307 09:27:38.895051 2997859264 sgd_solver.cpp:105] Iteration 640, lr = 0.001
I0307 09:27:44.226385 2997859264 solver.cpp:219] Iteration 650 (1.87582 iter/s, 5.331s/10 iters), loss = 0.0989582
I0307 09:27:44.226428 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0989582 (* 1 = 0.0989582 loss)
I0307 09:27:44.226439 2997859264 sgd_solver.cpp:105] Iteration 650, lr = 0.001
I0307 09:27:49.562146 2997859264 solver.cpp:219] Iteration 660 (1.87441 iter/s, 5.335s/10 iters), loss = 0.069531
I0307 09:27:49.563000 2997859264 solver.cpp:238]     Train net output #0: loss = 0.069531 (* 1 = 0.069531 loss)
I0307 09:27:49.563024 2997859264 sgd_solver.cpp:105] Iteration 660, lr = 0.001
I0307 09:27:53.618273 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:27:55.293361 2997859264 solver.cpp:219] Iteration 670 (1.7452 iter/s, 5.73s/10 iters), loss = 0.0879414
I0307 09:27:55.293395 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0879414 (* 1 = 0.0879414 loss)
I0307 09:27:55.293402 2997859264 sgd_solver.cpp:105] Iteration 670, lr = 0.001
I0307 09:28:01.211655 2997859264 solver.cpp:219] Iteration 680 (1.68976 iter/s, 5.918s/10 iters), loss = 0.112576
I0307 09:28:01.211685 2997859264 solver.cpp:238]     Train net output #0: loss = 0.112576 (* 1 = 0.112576 loss)
I0307 09:28:01.211693 2997859264 sgd_solver.cpp:105] Iteration 680, lr = 0.001
I0307 09:28:06.578145 2997859264 solver.cpp:219] Iteration 690 (1.86359 iter/s, 5.366s/10 iters), loss = 0.108427
I0307 09:28:06.578176 2997859264 solver.cpp:238]     Train net output #0: loss = 0.108427 (* 1 = 0.108427 loss)
I0307 09:28:06.578184 2997859264 sgd_solver.cpp:105] Iteration 690, lr = 0.001
I0307 09:28:11.440927 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_700.caffemodel
I0307 09:28:11.513840 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_700.solverstate
I0307 09:28:11.541945 2997859264 solver.cpp:331] Iteration 700, Testing net (#0)
I0307 09:28:11.607790 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:28:11.846987 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.95
I0307 09:28:11.847018 2997859264 solver.cpp:398]     Test net output #1: loss = 0.143875 (* 1 = 0.143875 loss)
I0307 09:28:12.380383 2997859264 solver.cpp:219] Iteration 700 (1.72354 iter/s, 5.802s/10 iters), loss = 0.123765
I0307 09:28:12.380414 2997859264 solver.cpp:238]     Train net output #0: loss = 0.123765 (* 1 = 0.123765 loss)
I0307 09:28:12.380421 2997859264 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0307 09:28:17.703549 2997859264 solver.cpp:219] Iteration 710 (1.87864 iter/s, 5.323s/10 iters), loss = 0.11015
I0307 09:28:17.703582 2997859264 solver.cpp:238]     Train net output #0: loss = 0.11015 (* 1 = 0.11015 loss)
I0307 09:28:17.703588 2997859264 sgd_solver.cpp:105] Iteration 710, lr = 0.001
I0307 09:28:18.295361 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:28:23.586057 2997859264 solver.cpp:219] Iteration 720 (1.7001 iter/s, 5.882s/10 iters), loss = 0.0738848
I0307 09:28:23.586426 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0738848 (* 1 = 0.0738848 loss)
I0307 09:28:23.586439 2997859264 sgd_solver.cpp:105] Iteration 720, lr = 0.001
I0307 09:28:28.950186 2997859264 solver.cpp:219] Iteration 730 (1.86463 iter/s, 5.363s/10 iters), loss = 0.0829806
I0307 09:28:28.950217 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0829806 (* 1 = 0.0829806 loss)
I0307 09:28:28.950227 2997859264 sgd_solver.cpp:105] Iteration 730, lr = 0.001
I0307 09:28:34.100239 2997859264 solver.cpp:219] Iteration 740 (1.94175 iter/s, 5.15s/10 iters), loss = 0.125545
I0307 09:28:34.100270 2997859264 solver.cpp:238]     Train net output #0: loss = 0.125545 (* 1 = 0.125545 loss)
I0307 09:28:34.100276 2997859264 sgd_solver.cpp:105] Iteration 740, lr = 0.001
I0307 09:28:39.467180 2997859264 solver.cpp:219] Iteration 750 (1.86359 iter/s, 5.366s/10 iters), loss = 0.102809
I0307 09:28:39.467211 2997859264 solver.cpp:238]     Train net output #0: loss = 0.102809 (* 1 = 0.102809 loss)
I0307 09:28:39.467219 2997859264 sgd_solver.cpp:105] Iteration 750, lr = 0.001
I0307 09:28:42.618412 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:28:45.037930 2997859264 solver.cpp:219] Iteration 760 (1.79533 iter/s, 5.57s/10 iters), loss = 0.0926182
I0307 09:28:45.037962 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0926182 (* 1 = 0.0926182 loss)
I0307 09:28:45.037971 2997859264 sgd_solver.cpp:105] Iteration 760, lr = 0.001
I0307 09:28:50.902709 2997859264 solver.cpp:219] Iteration 770 (1.70532 iter/s, 5.864s/10 iters), loss = 0.108119
I0307 09:28:50.902740 2997859264 solver.cpp:238]     Train net output #0: loss = 0.108119 (* 1 = 0.108119 loss)
I0307 09:28:50.902748 2997859264 sgd_solver.cpp:105] Iteration 770, lr = 0.001
I0307 09:28:56.700959 2997859264 solver.cpp:219] Iteration 780 (1.72473 iter/s, 5.798s/10 iters), loss = 0.0999188
I0307 09:28:56.701274 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0999188 (* 1 = 0.0999188 loss)
I0307 09:28:56.701284 2997859264 sgd_solver.cpp:105] Iteration 780, lr = 0.001
I0307 09:29:02.282002 2997859264 solver.cpp:219] Iteration 790 (1.79211 iter/s, 5.58s/10 iters), loss = 0.102896
I0307 09:29:02.282034 2997859264 solver.cpp:238]     Train net output #0: loss = 0.102896 (* 1 = 0.102896 loss)
I0307 09:29:02.282042 2997859264 sgd_solver.cpp:105] Iteration 790, lr = 0.001
I0307 09:29:07.052644 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_800.caffemodel
I0307 09:29:07.128988 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_800.solverstate
I0307 09:29:07.159672 2997859264 solver.cpp:331] Iteration 800, Testing net (#0)
I0307 09:29:07.278911 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:29:07.451882 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.943333
I0307 09:29:07.451915 2997859264 solver.cpp:398]     Test net output #1: loss = 0.133778 (* 1 = 0.133778 loss)
I0307 09:29:07.965495 2997859264 solver.cpp:219] Iteration 800 (1.75963 iter/s, 5.683s/10 iters), loss = 0.116647
I0307 09:29:07.965528 2997859264 solver.cpp:238]     Train net output #0: loss = 0.116647 (* 1 = 0.116647 loss)
I0307 09:29:07.965535 2997859264 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0307 09:29:08.486632 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:29:13.383265 2997859264 solver.cpp:219] Iteration 810 (1.84604 iter/s, 5.417s/10 iters), loss = 0.100309
I0307 09:29:13.383294 2997859264 solver.cpp:238]     Train net output #0: loss = 0.100309 (* 1 = 0.100309 loss)
I0307 09:29:13.383301 2997859264 sgd_solver.cpp:105] Iteration 810, lr = 0.001
I0307 09:29:19.293443 2997859264 solver.cpp:219] Iteration 820 (1.69205 iter/s, 5.91s/10 iters), loss = 0.079807
I0307 09:29:19.293509 2997859264 solver.cpp:238]     Train net output #0: loss = 0.079807 (* 1 = 0.079807 loss)
I0307 09:29:19.293524 2997859264 sgd_solver.cpp:105] Iteration 820, lr = 0.001
I0307 09:29:25.154027 2997859264 solver.cpp:219] Iteration 830 (1.70648 iter/s, 5.86s/10 iters), loss = 0.0737241
I0307 09:29:25.154060 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0737241 (* 1 = 0.0737241 loss)
I0307 09:29:25.154068 2997859264 sgd_solver.cpp:105] Iteration 830, lr = 0.001
I0307 09:29:30.524950 2997859264 solver.cpp:219] Iteration 840 (1.8622 iter/s, 5.37s/10 iters), loss = 0.0869684
I0307 09:29:30.525969 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0869684 (* 1 = 0.0869684 loss)
I0307 09:29:30.526003 2997859264 sgd_solver.cpp:105] Iteration 840, lr = 0.001
I0307 09:29:33.166925 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:29:35.742396 2997859264 solver.cpp:219] Iteration 850 (1.91718 iter/s, 5.216s/10 iters), loss = 0.0868984
I0307 09:29:35.742434 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0868984 (* 1 = 0.0868984 loss)
I0307 09:29:35.742442 2997859264 sgd_solver.cpp:105] Iteration 850, lr = 0.001
I0307 09:29:40.961094 2997859264 solver.cpp:219] Iteration 860 (1.91644 iter/s, 5.218s/10 iters), loss = 0.0844686
I0307 09:29:40.961128 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0844686 (* 1 = 0.0844686 loss)
I0307 09:29:40.961136 2997859264 sgd_solver.cpp:105] Iteration 860, lr = 0.001
I0307 09:29:46.556437 2997859264 solver.cpp:219] Iteration 870 (1.78731 iter/s, 5.595s/10 iters), loss = 0.0931495
I0307 09:29:46.556469 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0931495 (* 1 = 0.0931495 loss)
I0307 09:29:46.556478 2997859264 sgd_solver.cpp:105] Iteration 870, lr = 0.001
I0307 09:29:52.189893 2997859264 solver.cpp:219] Iteration 880 (1.77525 iter/s, 5.633s/10 iters), loss = 0.102807
I0307 09:29:52.189927 2997859264 solver.cpp:238]     Train net output #0: loss = 0.102807 (* 1 = 0.102807 loss)
I0307 09:29:52.189935 2997859264 sgd_solver.cpp:105] Iteration 880, lr = 0.001
I0307 09:29:57.946578 2997859264 solver.cpp:219] Iteration 890 (1.73732 iter/s, 5.756s/10 iters), loss = 0.0864469
I0307 09:29:57.946617 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0864469 (* 1 = 0.0864469 loss)
I0307 09:29:57.946627 2997859264 sgd_solver.cpp:105] Iteration 890, lr = 0.001
I0307 09:29:57.958305 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:30:02.958986 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_900.caffemodel
I0307 09:30:03.051134 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_900.solverstate
I0307 09:30:03.088630 2997859264 solver.cpp:331] Iteration 900, Testing net (#0)
I0307 09:30:03.255545 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:30:03.436138 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.953333
I0307 09:30:03.436172 2997859264 solver.cpp:398]     Test net output #1: loss = 0.144225 (* 1 = 0.144225 loss)
I0307 09:30:04.030237 2997859264 solver.cpp:219] Iteration 900 (1.64393 iter/s, 6.083s/10 iters), loss = 0.0879387
I0307 09:30:04.030274 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0879387 (* 1 = 0.0879387 loss)
I0307 09:30:04.030283 2997859264 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0307 09:30:09.923672 2997859264 solver.cpp:219] Iteration 910 (1.69693 iter/s, 5.893s/10 iters), loss = 0.075394
I0307 09:30:09.923702 2997859264 solver.cpp:238]     Train net output #0: loss = 0.075394 (* 1 = 0.075394 loss)
I0307 09:30:09.923708 2997859264 sgd_solver.cpp:105] Iteration 910, lr = 0.001
I0307 09:30:15.903609 2997859264 solver.cpp:219] Iteration 920 (1.67252 iter/s, 5.979s/10 iters), loss = 0.0532053
I0307 09:30:15.903658 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0532053 (* 1 = 0.0532053 loss)
I0307 09:30:15.903672 2997859264 sgd_solver.cpp:105] Iteration 920, lr = 0.001
I0307 09:30:21.456913 2997859264 solver.cpp:219] Iteration 930 (1.80083 iter/s, 5.553s/10 iters), loss = 0.117445
I0307 09:30:21.456946 2997859264 solver.cpp:238]     Train net output #0: loss = 0.117445 (* 1 = 0.117445 loss)
I0307 09:30:21.456954 2997859264 sgd_solver.cpp:105] Iteration 930, lr = 0.001
I0307 09:30:24.286324 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:30:27.091536 2997859264 solver.cpp:219] Iteration 940 (1.77494 iter/s, 5.634s/10 iters), loss = 0.0934291
I0307 09:30:27.091576 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0934291 (* 1 = 0.0934291 loss)
I0307 09:30:27.091588 2997859264 sgd_solver.cpp:105] Iteration 940, lr = 0.001
I0307 09:30:32.402149 2997859264 solver.cpp:219] Iteration 950 (1.88324 iter/s, 5.31s/10 iters), loss = 0.0859955
I0307 09:30:32.402180 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0859955 (* 1 = 0.0859955 loss)
I0307 09:30:32.402189 2997859264 sgd_solver.cpp:105] Iteration 950, lr = 0.001
I0307 09:30:37.528991 2997859264 solver.cpp:219] Iteration 960 (1.95084 iter/s, 5.126s/10 iters), loss = 0.0865718
I0307 09:30:37.530046 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0865718 (* 1 = 0.0865718 loss)
I0307 09:30:37.530066 2997859264 sgd_solver.cpp:105] Iteration 960, lr = 0.001
I0307 09:30:43.096344 2997859264 solver.cpp:219] Iteration 970 (1.79662 iter/s, 5.566s/10 iters), loss = 0.0855992
I0307 09:30:43.096374 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0855992 (* 1 = 0.0855992 loss)
I0307 09:30:43.096381 2997859264 sgd_solver.cpp:105] Iteration 970, lr = 0.001
I0307 09:30:48.258906 2997859264 solver.cpp:219] Iteration 980 (1.93723 iter/s, 5.162s/10 iters), loss = 0.101723
I0307 09:30:48.258939 2997859264 solver.cpp:238]     Train net output #0: loss = 0.101723 (* 1 = 0.101723 loss)
I0307 09:30:48.258945 2997859264 sgd_solver.cpp:105] Iteration 980, lr = 0.001
I0307 09:30:48.266274 76939264 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:30:53.396483 2997859264 solver.cpp:219] Iteration 990 (1.94666 iter/s, 5.137s/10 iters), loss = 0.0874652
I0307 09:30:53.396522 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0874652 (* 1 = 0.0874652 loss)
I0307 09:30:53.396533 2997859264 sgd_solver.cpp:105] Iteration 990, lr = 0.001
I0307 09:30:58.005905 2997859264 solver.cpp:448] Snapshotting to binary proto file model_snapshot/snap_fe_iter_1000.caffemodel
I0307 09:30:58.076119 2997859264 sgd_solver.cpp:273] Snapshotting solver state to binary proto file model_snapshot/snap_fe_iter_1000.solverstate
I0307 09:30:58.106315 2997859264 solver.cpp:331] Iteration 1000, Testing net (#0)
I0307 09:30:58.279971 77475840 data_layer.cpp:73] Restarting data prefetching from start.
I0307 09:30:58.399173 2997859264 solver.cpp:398]     Test net output #0: accuracy = 0.963333
I0307 09:30:58.399204 2997859264 solver.cpp:398]     Test net output #1: loss = 0.116952 (* 1 = 0.116952 loss)
I0307 09:30:58.905079 2997859264 solver.cpp:219] Iteration 1000 (1.81554 iter/s, 5.508s/10 iters), loss = 0.0967072
I0307 09:30:58.905119 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0967072 (* 1 = 0.0967072 loss)
I0307 09:30:58.905129 2997859264 sgd_solver.cpp:105] Iteration 1000, lr = 0.0001
I0307 09:31:04.126687 2997859264 solver.cpp:219] Iteration 1010 (1.91534 iter/s, 5.221s/10 iters), loss = 0.0828288
I0307 09:31:04.126718 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0828288 (* 1 = 0.0828288 loss)
I0307 09:31:04.126727 2997859264 sgd_solver.cpp:105] Iteration 1010, lr = 0.0001
I0307 09:31:09.171047 2997859264 solver.cpp:219] Iteration 1020 (1.98255 iter/s, 5.044s/10 iters), loss = 0.0803325
I0307 09:31:09.171102 2997859264 solver.cpp:238]     Train net output #0: loss = 0.0803325 (* 1 = 0.0803325 loss)
I0307 09:31:09.171110 2997859264 sgd_solver.cpp:105] Iteration 1020, lr = 0.0001
I0307 09:31:11.187660 76939264 data_layer.cpp:73] Restarting data prefetching from start.
